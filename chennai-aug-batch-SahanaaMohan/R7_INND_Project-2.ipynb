{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahanaa_M\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AS data file is in H5 document, using h5py package to read the file\n",
    "f = h5py.File('SVHN_single_grey1.h5', 'r')\n",
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Train and Test data from the file\n",
    "x_train = f.get('X_train')\n",
    "y_train = f.get('y_train')\n",
    "x_test = f.get('X_test')\n",
    "y_test = f.get('y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in Training dataset:  42000\n",
      "Number of samples in Test dataset:  18000\n",
      "Dimensions of the image: (32, 32)\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples in Training dataset: ', x_train.shape[0])\n",
    "print('Number of samples in Test dataset: ', x_test.shape[0])\n",
    "print('Dimensions of the image:', x_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lst = []\n",
    "\n",
    "for x in x_train:\n",
    "    x = x.astype('float32')\n",
    "    x /= 255\n",
    "    x_train_lst.append(x.reshape(1024))\n",
    "\n",
    "x_train_df = pd.DataFrame(x_train_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(n_neighbors=5)  \n",
    "classifier.fit(x_train_df, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing Test Data\n",
    "x_test_lst = []\n",
    "\n",
    "for x in x_test:\n",
    "    x = x.astype('float32')\n",
    "    x /= 255\n",
    "    x_test_lst.append(x.reshape(1024))\n",
    "\n",
    "x_test_df = pd.DataFrame(x_test_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test_df.iloc[0:1000,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[77  8  1  2  2  2  8  1  7  9]\n",
      " [ 3 72  4  5  4  1  2  2  0  0]\n",
      " [10 18 41  5  1  1  2  4  4  6]\n",
      " [ 9 10 10 36  2  6  3  1  3  5]\n",
      " [11 14  3  2 58  1  2  2  2  1]\n",
      " [11 12  3 15  3 41  5  1  6  8]\n",
      " [13  7  2  2 13 10 38  0  7  2]\n",
      " [ 6 16  7  1  1  1  0 71  1  3]\n",
      " [22  9  4  3  3  6  8  2 39  4]\n",
      " [20  8  5  8  5  4  7  4 10 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.66      0.52       117\n",
      "           1       0.41      0.77      0.54        93\n",
      "           2       0.51      0.45      0.48        92\n",
      "           3       0.46      0.42      0.44        85\n",
      "           4       0.63      0.60      0.62        96\n",
      "           5       0.56      0.39      0.46       105\n",
      "           6       0.51      0.40      0.45        94\n",
      "           7       0.81      0.66      0.73       107\n",
      "           8       0.49      0.39      0.44       100\n",
      "           9       0.51      0.36      0.42       111\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      1000\n",
      "   macro avg       0.53      0.51      0.51      1000\n",
      "weighted avg       0.53      0.51      0.51      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test[0:1000,], y_pred))\n",
    "print(classification_report(y_test[0:1000,], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Accuracy with With KNN the prediction was between 50-60%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_neural = x_train.value\n",
    "x_test_neural = x_test.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_neural = x_train_neural.astype('float32')\n",
    "x_test_neural = x_test_neural.astype('float32')\n",
    "\n",
    "x_train_neural /= 255\n",
    "x_test_neural /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_neural = x_train_neural.reshape(x_train_neural.shape[0], 32, 32, 1).astype('float32')\n",
    "x_test_neural = x_test_neural.reshape(x_test_neural.shape[0], 32, 32, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing a Deep Neural Network Classifier with\n",
    "1. RELU Activations\n",
    "2. Batch Normalisation\n",
    "3. Cost Functions\n",
    "4. Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 544s 13ms/step - loss: 0.8589 - acc: 0.7318 - val_loss: 0.5947 - val_acc: 0.8207\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 327s 8ms/step - loss: 0.5086 - acc: 0.8454 - val_loss: 0.4834 - val_acc: 0.8554\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 347s 8ms/step - loss: 0.4098 - acc: 0.8747 - val_loss: 0.5072 - val_acc: 0.8496\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 321s 8ms/step - loss: 0.3391 - acc: 0.8956 - val_loss: 0.4776 - val_acc: 0.8588\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 320s 8ms/step - loss: 0.2888 - acc: 0.9121 - val_loss: 0.4628 - val_acc: 0.8715\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 318s 8ms/step - loss: 0.2439 - acc: 0.9244 - val_loss: 0.4549 - val_acc: 0.8743\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 325s 8ms/step - loss: 0.2015 - acc: 0.9379 - val_loss: 0.5450 - val_acc: 0.8479\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 317s 8ms/step - loss: 0.1758 - acc: 0.9437 - val_loss: 0.5212 - val_acc: 0.8617\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 324s 8ms/step - loss: 0.1509 - acc: 0.9518 - val_loss: 0.5650 - val_acc: 0.8532\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 321s 8ms/step - loss: 0.1403 - acc: 0.9550 - val_loss: 0.5130 - val_acc: 0.8701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20e8f5e9ef0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Conv Layer\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 1)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 2nd Conv Layer\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Batch Normalisation\n",
    "model.add(tensorflow.keras.layers.BatchNormalization())\n",
    "\n",
    "# Prediction Layer\n",
    "model.add(Dense(10,kernel_initializer='he_normal', use_bias=True))\n",
    "#model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Loss and Optimizer\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "# Store Training Results\n",
    "early_stopping = tensorflow.keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
    "callback_list = [early_stopping]\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_neural, y_train.value, batch_size=32, epochs=10,\n",
    "           validation_data=(x_test_neural, y_test.value), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nn = model.predict(x_test_neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  7\n",
       "2  2\n",
       "3  9\n",
       "4  0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lst = np.argmax(y_pred_nn, axis=1)\n",
    "y_pred_df = pd.DataFrame(y_pred_lst)\n",
    "y_pred_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1691   31    9   10    8    5   15    7   18   20]\n",
      " [  36 1633    9   34   42   10   11   30   19    4]\n",
      " [  20   26 1592   36   29    6    5   33   22   34]\n",
      " [  21   22   13 1466   24   73   27   12   44   17]\n",
      " [  14   50   18   24 1622   17   21    6   17   23]\n",
      " [   8   15    5   95   13 1504   73    7   30   18]\n",
      " [  62   18    4   34   28   50 1540    4   83    9]\n",
      " [  34   91   33   35   12   10    8 1560   13   12]\n",
      " [  30   34   17   47   14   21   64    9 1539   37]\n",
      " [  61   23   26   41   22   32   12   10   63 1514]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89      1814\n",
      "           1       0.84      0.89      0.87      1828\n",
      "           2       0.92      0.88      0.90      1803\n",
      "           3       0.80      0.85      0.83      1719\n",
      "           4       0.89      0.90      0.89      1812\n",
      "           5       0.87      0.85      0.86      1768\n",
      "           6       0.87      0.84      0.85      1832\n",
      "           7       0.93      0.86      0.90      1808\n",
      "           8       0.83      0.85      0.84      1812\n",
      "           9       0.90      0.84      0.87      1804\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     18000\n",
      "   macro avg       0.87      0.87      0.87     18000\n",
      "weighted avg       0.87      0.87      0.87     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_df))  \n",
    "print(classification_report(y_test, y_pred_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN Accuracy in ML: 50 - 60%\n",
    "##### Accuracy in DL: 85%\n",
    "\n",
    "##### Deep Learning Models perform well for image dataset\n",
    "\n",
    "Deep Learning model accuracy is 30% more than tradtional ML (KNN) in this case.\n",
    "EDL is not requried in DL, requires comparitevly less effort.\n",
    "In DL, we get to see the loss and accuracy while running each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
